{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Pattern Recognition - Solution 3: K-means and EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "78-2-HFZmy1C"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy import stats\n",
    "plt.rc('font', size=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gaussian(ax, mean, cov, color='red', size=3):\n",
    "    # draws ellipses representing different standard deviations (size is the number of ellipses)\n",
    "    # width and height are times by 2 since sqrt of the eigenval only measures half the distance\n",
    "    eig_w, eig_v = np.linalg.eig(cov)\n",
    "    # eigenvectors are orthogonal so we only need to check the first one\n",
    "    eig_v_0 = eig_v[0]\n",
    "    # arccos of first eigenvectors x coordinate will give us the angle\n",
    "    angle = np.arccos(eig_v_0[0])\n",
    "    # however, this only works for angles in [0, pi]\n",
    "    # for angles in [pi, 2*pi] we need to consider the\n",
    "    # y coordinate, too\n",
    "    if eig_v_0[1] > 0:\n",
    "        angle = 2 * np.pi - angle\n",
    "    angle = np.rad2deg(angle)\n",
    "\n",
    "    for i in range(size):\n",
    "        ell = Ellipse(xy=[mean[0], mean[1]],\n",
    "                      width=np.sqrt(eig_w[0]) * 2 * (i + 1),\n",
    "                      height=np.sqrt(eig_w[1]) * 2 * (i + 1),\n",
    "                      angle=angle,\n",
    "                      edgecolor=color, lw=2, facecolor='none')\n",
    "        ax.add_artist(ell)\n",
    "    print(mean)\n",
    "    ax.plot(mean[0], mean[1], \"x\", c=color, ms=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0hzVF3knGGa"
   },
   "source": [
    "## $\\star$ Part 1: K-means and EM with sklearn\n",
    "\n",
    "Run the Sklearn implementations of k-means and expectation maximization on the dataset *gaussianplus.npz*.\n",
    "\n",
    "\n",
    "Plot the estimated assignments and the estimated\n",
    "parameters of the two Gaussians. \n",
    "\n",
    "Describe how the fitting by expectation maximization outperforms the one with k-means.\n",
    "\n",
    "Try with varying, also\n",
    "very bad initializations. How stable are the results?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VzPFK-xXnJi0"
   },
   "outputs": [],
   "source": [
    "# Load and visualize the dataset (as in previous exercises):\n",
    "\n",
    "# START TODO #################\n",
    "raise NotImplementedError\n",
    "# END TODO #################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.1: Run K-Means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_and_plot_k_means(data, init='random', k=2):\n",
    "    \"\"\"\n",
    "    Runs the K-means algorithm from sklearn on the input data and plots the results.\n",
    "\n",
    "    Args:\n",
    "        data: Input data.\n",
    "        init: Initialization method (see the sklearn documentation).\n",
    "        k : Number of clusters.\n",
    "    \"\"\"\n",
    "\n",
    "    # Apply the K-Means clustering implementation from sklearn (see documentation for usage instructions).\n",
    "    # Store the cluster assignments in a variable called 'labels' and the cluster centroids in a\n",
    "    # variable called 'centroids':\n",
    "    # START TODO #################\n",
    "    raise NotImplementedError\n",
    "    # END TODO #################\n",
    "\n",
    "    # Print centroids:\n",
    "    # START TODO #################\n",
    "    raise NotImplementedError\n",
    "    # END TODO #################\n",
    "\n",
    "    # Plot results (plot datapoints and centroids; color points according to the cluster assignment):\n",
    "    # START TODO #################\n",
    "    raise NotImplementedError\n",
    "    # END TODO #################\n",
    "\n",
    "\n",
    "# run with random init:\n",
    "run_and_plot_k_means(data, init='random')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run with manual init:\n",
    "run_and_plot_k_means(data, init=np.array([[16,16], [14,14]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.2: Run EM algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_and_plot_em(data, means_init=None, k=2):\n",
    "    \"\"\"\n",
    "    Runs the EM algorithm from sklearn on the input data and plots the results.\n",
    "\n",
    "    Args:\n",
    "        data: Input data.\n",
    "        means_init: Initial means of the gaussians.\n",
    "        k: Number of mixture components.\n",
    "    \"\"\"\n",
    "    # Apply the EM-algorithm implementation from sklearn (see documentation for usage instructions).\n",
    "    # Store the cluster assignments in a variable called 'labels', the estimated means in a variable 'means',\n",
    "    # the estimated weights in a variable 'weights' and the estimated covariances in a variable 'covariances':\n",
    "    # START TODO #################\n",
    "    raise NotImplementedError\n",
    "    # END TODO #################\n",
    "\n",
    "    # Print means and mixture weights:\n",
    "    # START TODO #################\n",
    "    raise NotImplementedError\n",
    "    # END TODO #################\n",
    "\n",
    "    # Plot results:\n",
    "    # (plot datapoints and centroids; color points according to the cluster assignment;\n",
    "    # plot covariances with the plot_gaussian function)\n",
    "    # START TODO #################\n",
    "    raise NotImplementedError\n",
    "    # END TODO #################\n",
    "\n",
    "\n",
    "# run with random init:\n",
    "run_and_plot_em(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run with manual init:\n",
    "run_and_plot_em(data, means_init=np.array([[16,16], [10,10]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w6kyRTFRnJ6j"
   },
   "source": [
    "# $\\star\\star\\star$ Part 2: Custom k-means and EM\n",
    "\n",
    "Build your own implementations of k-means and EM to learn in\n",
    "detail how these important algorithms work.\n",
    "\n",
    "Compare your implementation with the sklearn\n",
    "implementation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_ySDrzknOpV"
   },
   "source": [
    "### Part 2.1: Custom K-means implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleKMeans:\n",
    "    def __init__(self, k, mean_init, num_iters=100):\n",
    "        \"\"\"Custom k-means implementation.\n",
    "\n",
    "        Args:\n",
    "            k: Number of clusters.\n",
    "            mean_init: Initial cluster means as np array of shape (num_clusters, dimensions).\n",
    "            num_iters: Number of iterations.\n",
    "        \"\"\"\n",
    "        self.centroids = mean_init.astype(float)\n",
    "        self.labels = None\n",
    "        self.num_iters = num_iters\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, data):\n",
    "        # run k-means on the data and store results in self.centroids and self.labels:\n",
    "        # START TODO #################\n",
    "        raise NotImplementedError\n",
    "        # END TODO #################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_and_plot_simple_k_means(data, init=np.array([[4,4], [10,4]]), k=2, num_iters=10):\n",
    "    \"\"\"Runs the custom K-means implementation on the input data and plots the results.\n",
    "\n",
    "    Args:\n",
    "        data: Input data.\n",
    "        init: Initial cluster centroids.\n",
    "        k : Number of clusters.\n",
    "        num_iters : Number of iterations.\n",
    "    \"\"\"\n",
    "    # Apply the custom K-Means clustering implementation.\n",
    "    # Store the cluster assignments in a variable called 'labels' and the cluster centroids in a\n",
    "    # variable called 'centroids':\n",
    "    # START TODO #################\n",
    "    raise NotImplementedError\n",
    "    # END TODO #################\n",
    "\n",
    "    # Print centroids:\n",
    "    # START TODO #################\n",
    "    raise NotImplementedError\n",
    "    # END TODO #################\n",
    "\n",
    "    # Plot results (plot datapoints and centroids; color points according to the cluster assignment):\n",
    "    # START TODO #################\n",
    "    raise NotImplementedError\n",
    "    # END TODO #################\n",
    "\n",
    "\n",
    "# Run our implementation of simple k-means:\n",
    "run_and_plot_simple_k_means(data, init=np.array([[6,6], [4,5] ]), k=2, num_iters=10)\n",
    "\n",
    "\n",
    "# Compare to the sklearn implementation of k-means:\n",
    "run_and_plot_k_means(data, init=np.array([[6,6], [4,5]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.2: Custom EM algorithm implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleEM:\n",
    "    def __init__(self, means_init=None, k=2, num_iters=10):\n",
    "        # initialize attributes:\n",
    "        # START TODO #################\n",
    "        raise NotImplementedError\n",
    "        # END TODO #################\n",
    "\n",
    "    # START TODO #################\n",
    "    raise NotImplementedError\n",
    "    # END TODO #################\n",
    "\n",
    "    def fit(self, data):\n",
    "        # run the em algorithm on the data and store results self.means, self.sigmas, self.pi, self.labels:\n",
    "        # START TODO #################\n",
    "        raise NotImplementedError\n",
    "        # END TODO #################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run_and_plot_simple_em(data, means_init=None, k=2, num_iters=10):\n",
    "    \"\"\"\n",
    "    Runs the custom EM algorithm implementation on the input data and plots the results.\n",
    "\n",
    "    Args:\n",
    "        data: Input data.\n",
    "        means_init: Initial means of the gaussians.\n",
    "        k: Number of mixture components.\n",
    "        num_iters: Number of iterations.\n",
    "    \"\"\"\n",
    "    # Apply the custom EM-algorithm implementation.\n",
    "    # Store the cluster assignments in a variable called 'labels', the estimated means in a variable 'means',\n",
    "    # the estimated weights in a variable 'weights' and the estimated covariances in a variable 'covariances':\n",
    "    # START TODO #################\n",
    "    raise NotImplementedError\n",
    "    # END TODO #################\n",
    "\n",
    "    # Print means and mixture weights:\n",
    "    # START TODO #################\n",
    "    raise NotImplementedError\n",
    "    # END TODO #################\n",
    "\n",
    "    # Plot results:\n",
    "    # (plot datapoints and centroids; color points according to the cluster assignment;\n",
    "    # plot covariances with the plot_gaussian function)\n",
    "    # START TODO #################\n",
    "    raise NotImplementedError\n",
    "    # END TODO #################\n",
    "\n",
    "# Run our implementation of the EM algorithm:\n",
    "run_and_plot_simple_em(data, k=2, num_iters=50)\n",
    "\n",
    "\n",
    "# Compare to the sklearn implementation of the EM algorithm:\n",
    "run_and_plot_em(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ex3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}