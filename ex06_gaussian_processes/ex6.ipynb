{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Pattern Recognition - Exercise 6: Gaussian processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fMGP7sA8B7ak"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define plot function \n",
    "\n",
    "We test it on [this example from sklearn](https://scikit-learn.org/stable/auto_examples/gaussian_process/plot_gpr_noisy_targets.html#sphx-glr-auto-examples-gaussian-process-plot-gpr-noisy-targets-py)\n",
    "\n",
    "To plot the 95% confidence interval we look up the z-score for the standard normal distribution.\n",
    "Assume a standard normal with mean 0, std 1, then for input value x=1.96 the cumulative density is 0.975.\n",
    "This means 97.5% of all probability mass is to the left of x.\n",
    "If we now cut off left of -1.96 and right of 1.96 we will have 95% of the probability mass inside those boundaries.\n",
    "\n",
    "```python\n",
    "# import scipy.stats\n",
    "# z_score = stats.norm.ppf(0.975)  # ~1.96\n",
    "```\n",
    "\n",
    "Ppf here means percent-point function (inverse of the cumulative density function or CDF) for a standard normal distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gp(mu, cov, x, x_train=None, y_train=None, label=\"Pred\"):\n",
    "    \"\"\"\n",
    "        mu: mean prediction, shape (N, 1)\n",
    "        cov: prediction covariance, shape (N, N)\n",
    "        x: inputs to predict for, shape (N, 1)\n",
    "        x_train: observation inputs, shape (N_obs, 1)\n",
    "        y_train: obersvation labels, shape (N_obs,)\n",
    "    \"\"\"\n",
    "    x, mu = x.ravel(), mu.ravel()  # flatten both to shape (N, )\n",
    "    uncertainty = 1.96 * np.sqrt(np.diag(cov))\n",
    "\n",
    "    plt.fill_between(x, mu + uncertainty, mu - uncertainty, alpha=0.1)\n",
    "    plt.plot(x, mu, label=label)\n",
    "\n",
    "    if x_train is not None:\n",
    "        n_samples = x_train.shape[0]\n",
    "        plt.plot(x_train, y_train, \"rx\", label=f\"{n_samples} train samples\")\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the gp example from sklearn\n",
    "e_x = np.linspace(start=0, stop=10, num=1_000).reshape(-1, 1)\n",
    "e_y = np.squeeze(e_x * np.sin(e_x))\n",
    "rng = np.random.RandomState(1)\n",
    "training_indices = rng.choice(np.arange(e_y.size), size=6, replace=False)\n",
    "e_x_train, e_y_train = e_x[training_indices], e_y[training_indices]\n",
    "kernel = 1 * RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2))\n",
    "gaussian_process = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)\n",
    "gaussian_process = GaussianProcessRegressor(kernel=kernel, optimizer=None)\n",
    "gaussian_process.fit(e_x_train, e_y_train)\n",
    "print(f\"{gaussian_process.kernel_=}\")\n",
    "\n",
    "# run our plot code\n",
    "mu, cov = gaussian_process.predict(e_x, return_cov=True)\n",
    "plot_gp(mu, cov, e_x, e_x_train, e_y_train)\n",
    "plt.show()\n",
    "\n",
    "# compare with sklearn's plot code\n",
    "mean_prediction, std_prediction = gaussian_process.predict(e_x, return_std=True)\n",
    "plt.plot(e_x, e_y, label=r\"$f(x) = x \\sin(x)$\", linestyle=\"dotted\")\n",
    "plt.scatter(e_x_train, e_y_train, label=\"Observations\")\n",
    "plt.plot(e_x, mean_prediction, label=\"Mean prediction\")\n",
    "plt.fill_between(\n",
    "    e_x.ravel(),\n",
    "    mean_prediction - 1.96 * std_prediction,\n",
    "    mean_prediction + 1.96 * std_prediction,\n",
    "    alpha=0.5,\n",
    "    label=r\"95% confidence interval\",\n",
    ")\n",
    "plt.legend()\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$f(x)$\")\n",
    "plt.title(\"Gaussian process regression on noise-free dataset\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kfV-0nQUB-rE"
   },
   "source": [
    "## $\\star$ Part 1: Gaussian process\n",
    "\n",
    "### Part 1.1: Run a Gaussian Process Regressor using sklearn\n",
    "\n",
    "Load the points from regression.npz. \n",
    "\n",
    "Estimate the mean prediction and the variance using a Gaussian process and plot both in the style of last weekâ€™s assignment. \n",
    "\n",
    "Use an RBF kernel (a Gaussian function). Play\n",
    "with the hyperparameters (which hyperparameters do you have?) and see\n",
    "the effect in the predictive distribution. \n",
    "\n",
    "Reduce the number of samples and\n",
    "repeat the experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Thb2wsjCUgQ"
   },
   "outputs": [],
   "source": [
    "# START TODO ################\n",
    "# Load data and reshape it into X_train shape (N, 1) and Y_train shape (N,)\n",
    "# Create a suitable range X_test for testing\n",
    "raise NotImplementedError\n",
    "# END TODO ################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START TODO ################\n",
    "# Create a function that fits a GP using sklearn and run the function on the data\n",
    "raise NotImplementedError\n",
    "# END TODO ################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START TODO ################\n",
    "# Randomly subsample your data and run the GP on [1, 2, 3, 5, 10, 20] datapoints.\n",
    "# What do you observe?\n",
    "raise NotImplementedError\n",
    "# END TODO ################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START TODO ################\n",
    "# Go back to the full dataset and play with the other hyperparameters.\n",
    "raise NotImplementedError\n",
    "# END TODO ################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.2: Now, implement your own rbf_kernel function and MyGPRegressor class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START TODO ################\n",
    "# Now, implement your own rbf_kernel function and MyGPRegressor class.\n",
    "raise NotImplementedError\n",
    "# END TODO ################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START TODO ################\n",
    "# Run your implementation on the data.\n",
    "raise NotImplementedError\n",
    "# END TODO ################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START TODO ################\n",
    "# Play with the beta parameter of MyGPRegressor and also length and sigma_f parameters of rbf_kernel\n",
    "# Observe how these *hyperparameters* change the data fit. Try to reason why you obtain these different results.\n",
    "raise NotImplementedError\n",
    "# END TODO ################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "ex6.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
